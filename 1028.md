**MeshFlow: Minimum Latency Online Video Stabilization**  2016

* DUT的前置
* 实时稳像
* FAST提取特征点 ，KLT计算特征点光流，图像切分为16*16网格，每个格点由领域eclipse的运动矢量决定，中值滤波过滤候选者；
  * FAST只能提取点的位置，没有其他描述信息（如尺度和方向），KLT是否可以自动把不同帧的key point配对？
* 对全图，另一个中值滤波用于移除特异点
* 每个格点的运动轨迹通过Predicted Adaptive Path Smoothing（PAPS）进行平滑
* meshflow主要的流程为“估计光流-->估计关键点并筛选出关键点的光流-->基于关键点光流得到mesh中每一个格点的motion/轨迹-->进行轨迹平滑并得到平滑后的轨迹/每一个格点的motion-->基于motion得到满足平滑轨迹的视频帧

**DUT: Learning Video Stabilization by Simply Watching Unstable Videos**  2020

* 在meshflow的框架下，将其中所有的模块都deep化：

  * LK光流---->PWCNet

  * SIFT关键点----->RFNet

  * 基于Median Filters的轨迹平滑------>可学习的1D卷积

* 无监督训练基于：continuity in motion and the consistency of keypoints and grid vertices before and after stabilization
* 三个网络，keypoint detection (KD), motion propagation (MP), and trajectory smoothing (TS)  



**RF-Net: An End-to-End Image Matching Network based on Receptive Field**  2019

* 文中提到Hand-crafted approaches like SIFT，参考
  * https://www.cnblogs.com/wangguchangqing/p/4853263.html
  * https://blog.csdn.net/qq_37374643/article/details/88606351
  * https://blog.csdn.net/zddblog/article/details/7521424
* 